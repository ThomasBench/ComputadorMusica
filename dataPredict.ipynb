{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import Tensor\n",
    "from model_helpers import preprocess_text\n",
    "import pickle\n",
    "from rnn_model import EncoderRNN, DecoderRNN\n",
    "import random\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"./model_trained/stored_dataset.pickle\"\n",
    "with open(dataset_path, 'rb') as f :\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "    \n",
    "# Load the encoder and decoder models\n",
    "encoder_path = \"./model_trained/encoder.pt\"\n",
    "decoder_path = \"./model_trained/decoder.pt\"\n",
    "input_size = 100\n",
    "hidden_size = 256\n",
    "output_size = len(dataset.chords_set)\n",
    "\n",
    "encoder = EncoderRNN(input_size, hidden_size, device)\n",
    "decoder = DecoderRNN(hidden_size, output_size, device)\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n",
    "decoder.load_state_dict(torch.load(decoder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to evaluate the model \n",
    "\n",
    "def predict(encoder, decoder, sentence, max_length=7039):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = Tensor([dataset.vectorize(w) for w in preprocess_text( sentence)]).to(device)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        decoder_input = torch.tensor([dataset.chord2id[dataset.draw_chord()[0]]], device=device)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = [random.sample(dataset.chords_set,1)[0]]\n",
    "        # decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(1,4):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            decoded_words.append(dataset.id2chord[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fm6', 'D#', 'A#', 'D#']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input your lyrics and Tadaaaaaa\n",
    "lyrics = '''\n",
    "Today is gonna be the day that they're gonna throw it back to you\n",
    "And by now, you should've somehow realised what you gotta do\n",
    "'''\n",
    "\n",
    "predict(encoder, decoder,lyrics )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c08fb7d0681ab80e3191df3cdd3d9ae56e033f792b7fa01572cc6446116ecae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
