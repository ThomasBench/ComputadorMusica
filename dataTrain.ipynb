{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim, Tensor\n",
    "import torch.functional as F\n",
    "from chords_dataset import ChordsDataset\n",
    "from model_helpers import NLP, preprocess_text, timeSince, asMinutes\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from typing import List\n",
    "from rnn_model import EncoderRNN, DecoderRNN\n",
    "plt.switch_backend('agg')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv('./model_data/lyrics_processed_2.csv')\n",
    "dataset = ChordsDataset(df, NLP)\n",
    "train_i, test_i, validation_i = dataset.get_train_test_valid_indexes(0.9,0.09,0.01)\n",
    "with open(\"stored_dataset.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dataset,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Train function \n",
    "\n",
    "def train(input_tensor: Tensor, target_tensor: Tensor,rarity_tensor: Tensor,  encoder: nn.Module, decoder: nn.Module, encoder_optimizer, decoder_optimizer, criterion, max_length=7039, teacher_forcing_ratio = 0.9):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = 4\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input =target_tensor[0].view(1,1).type(torch.LongTensor).to(device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoded = [decoder_input]\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(1,4):\n",
    "            decoder_output, decoder_hidden  = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(\n",
    "                decoder_output.view(1,-1,1).to(device),\n",
    "                target_tensor[di].view(1,1).type(torch.LongTensor).to(device)\n",
    "            )\n",
    "            decoded.append(decoder_output.topk(1)[1])\n",
    "            decoder_input = target_tensor[di].view(1,1).type(torch.LongTensor)    # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(1,4):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            decoded.append(topi)\n",
    "            loss += criterion(\n",
    "                decoder_output.view(1,-1,1).to(device),\n",
    "                target_tensor[di].view(1,1).type(torch.LongTensor).to(device)\n",
    "            )\n",
    "\n",
    "    weighted_loss = loss * rarity_tensor.item()\n",
    "    weighted_loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch train function \n",
    "\n",
    "def trainIters(encoder: nn.Module, decoder: nn.Module ,train_indexes: List[int], dataset: ChordsDataset, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for i,index in enumerate(train_indexes):\n",
    "        elem = dataset[index]\n",
    "        source, target, rarity = elem[\"lyrics\"].reshape(-1,1,100).to(device), elem[\"chords\"].reshape(-1,1).to(device), Tensor([elem[\"rarity\"]]).reshape(-1,1).to(device)\n",
    "        loss = train(source, target,rarity, encoder,\n",
    "                    decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if i % print_every == 1:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(timeSince(start, i / len(train_i)), (i / len(train_i)) * 100, print_loss_avg)\n",
    "\n",
    "        if i % print_every == 1:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        if i / len(train_i) > 0.45:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "output_dim = len(dataset.chords_set)\n",
    "encoder1 = EncoderRNN(100, hidden_size, device).to(device)\n",
    "attn_decoder1 = DecoderRNN(hidden_size, output_dim, device).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1,train_i, dataset, print_every=75, learning_rate= 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fdim/G#', 'F#', 'B', 'F#']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(encoder1.state_dict(), \"./model_trained/encoder.pt\")\n",
    "torch.save(attn_decoder1.state_dict(), \"./model_trained/decoder.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c08fb7d0681ab80e3191df3cdd3d9ae56e033f792b7fa01572cc6446116ecae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
